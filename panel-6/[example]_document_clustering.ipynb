{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bb046ae-f50b-4bbe-8562-0b0ed51a99a7",
   "metadata": {},
   "source": [
    "# Document Clustering with pandas, flair, and sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e39b0f0",
   "metadata": {},
   "source": [
    "Here the following Python packages are used to vectorize text and visualize it:  \n",
    "- **flair** is a NLP packages which is very powerful and well documented: https://flairnlp.github.io/docs/intro  \n",
    "- **numpy** is one of the most used packages for mathematical/vectorization purposes: https://numpy.org\n",
    "- **scikit-learn** (sklearn) is a well known and powerful Machine Learning package: https://scikit-learn.org/stable/index.html\n",
    "- **matplotlib** is a powerful package to visualize data: https://matplotlib.org \n",
    "- **pandas** is used to handle data, anlyse, and manipulate it fast and efficient: https://pandas.pydata.org "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4afacb-056f-4f32-9860-c76b71a5af6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install flair tqdm scikit-learn pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a9eb70-c727-4dbf-a89f-838dcacbc384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm # package to visualize progress\n",
    "\n",
    "# imports for the documents embeddings\n",
    "from flair.embeddings import TransformerDocumentEmbeddings\n",
    "from flair.data import Sentence\n",
    "\n",
    "# imports for clustering and pca\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# initiate pandas progress bar\n",
    "tqdm.pandas(ncols=50)\n",
    "\n",
    "# read the csv data\n",
    "# source: https://www.kaggle.com/datasets/notshrirang/spotify-million-song-dataset\n",
    "# despite it's name - there is not a million songs in it :)\n",
    "data = pd.read_csv('./spotify_millsongdata.csv')\n",
    "\n",
    "# some songs are probably more than one time in the data\n",
    "data.drop_duplicates(subset='text', inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb64d53-e6d4-425c-9926-a99ee2eedb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we load the data in a pandas dataframe\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5e15ad-26dc-4898-80d2-8d66bcb40d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to cluster, we choose four artists of different styles\n",
    "# hoping, their songtexts represent this\n",
    "chosen_artists = ['Bob Marley', 'Zucchero', 'Snoop Dogg', 'Alice Cooper']\n",
    "data = data[data['artist'].isin(chosen_artists)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07600251-f859-46b7-b252-279092ac1244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the filtered dataframe, where you can see the amount of songs of the artists\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19422d3f-80b4-4be5-8fbd-b28c366f86bf",
   "metadata": {},
   "source": [
    "### Embed, dimension reduction, and clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd6c37f-7716-472d-ad44-483ae8a32137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the roberta-large or roberta-base embedding to vectorize the text\n",
    "# the large ones needs more computational power\n",
    "# feel free to test other roberta (or bert) models: https://huggingface.co/models?pipeline_tag=fill-mask&library=transformers&language=en&sort=trending&search=roberta\n",
    "\n",
    "embedding = TransformerDocumentEmbeddings('distilroberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b335d4f9-b25a-43ad-afe9-c4e490cbc098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# progress_apply() does the same like apply(), it just visualizes the progress with tqdm\n",
    "# embedding takes place here\n",
    "data['text_embedding'] = data['text'].progress_apply(lambda x: embedding.embed(Sentence(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bdb779-3f1d-41bc-ae81-c04e6cc8bf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# thats how a vector looks like\n",
    "data.iloc[0,4][0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987b736c-4867-414f-83f7-941e524dc97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flair returns a sentence, we need the embedding of it\n",
    "data['embedding'] = data['text_embedding'].progress_apply(\n",
    "    lambda x: x[0].embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbcbcd6-b470-453d-ba1c-f01f81a01f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37ae2db-3b7f-41cb-b289-975419fa72df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the tensor data has to be standardized for PCA and clustering\n",
    "tensor_data = data['embedding'].values\n",
    "flattened_tensors = [tensor.flatten() for tensor in tensor_data]\n",
    "flattened_array = np.array(flattened_tensors)\n",
    "\n",
    "# standardize the flattened array\n",
    "scaler = StandardScaler()\n",
    "standardized_data = scaler.fit_transform(flattened_array)\n",
    "\n",
    "# apply PCA down to 2 dimensions for visualization\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(standardized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57219e6-09dd-4ae5-a57c-d6015cf31630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply agglomerative clustering (same amount of clusters as artist have been chosen)\n",
    "clustering = AgglomerativeClustering(\n",
    "    n_clusters=len(chosen_artists)\n",
    ")\n",
    "cluster_labels = clustering.fit_predict(standardized_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba4c900-df4b-4b38-be4a-0927754b3645",
   "metadata": {},
   "source": [
    "### Analyze the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9036a5b9-75d4-497b-b7be-375858632cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# names of the cluster_labels\n",
    "np.unique(cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7e49c1-a9c9-439a-92ee-b241d81cc581",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cluster_label'] = cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5059f2c-ec18-44a8-a771-002fbb64ecac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the results in a dataframe\n",
    "result = pd.DataFrame(data.value_counts(subset=['cluster_label', 'artist'])).sort_values(by=['cluster_label'])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a744bbdc-d516-44aa-9871-b9c6d93d1e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the index\n",
    "result = result.reset_index(drop=False)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34520cd1-9b17-4428-ab27-0670c45c9bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of strings for every cluster - needed for the visualization legend\n",
    "result_list = []\n",
    "\n",
    "for _, cluster_data in result.groupby('cluster_label'):\n",
    "    artist_counts = []\n",
    "    for index, row in cluster_data.iterrows():\n",
    "        artist_counts.append(f\"{row['artist']}: {row['count']}\")\n",
    "    result_list.append(artist_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ea4330-1877-4dd6-b1b5-9084d26abd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe62729-4db8-404f-bfd9-b877ac4cafd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the result\n",
    "fig = plt.figure(figsize=(10,16))\n",
    "ax = plt.subplot(211)\n",
    "\n",
    "scatter = ax.scatter(pca_result[:, 0], pca_result[:, 1], c=cluster_labels, cmap='rainbow')\n",
    "\n",
    "# create a readable legend\n",
    "legend_labels = ['\\n'.join(l) for l in result_list]\n",
    "handles = scatter.legend_elements(num=[0,1,2,3])[0]\n",
    "ax.legend(\n",
    "    handles=handles,\n",
    "    labels=legend_labels,\n",
    "    bbox_to_anchor=(1,0.5),\n",
    "    loc='center left',\n",
    "    fontsize=10,\n",
    "    shadow=True,\n",
    ")\n",
    "\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('Agglomerative Clustering Result')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba69e5ce-1f97-4d9f-bee8-e550b9c10f47",
   "metadata": {},
   "source": [
    "Maybe compare some **songtexts** you wouldn't expect to be in the same cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2c4bf4-1753-40a4-9ac4-3b5c0002282a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
